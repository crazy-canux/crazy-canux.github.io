<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Hadoop on Morgoth</title>
        <link>https://canuxcheng.com/tags/hadoop/</link>
        <description>Recent content in Hadoop on Morgoth</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Wed, 03 May 2017 22:57:37 +0000</lastBuildDate><atom:link href="https://canuxcheng.com/tags/hadoop/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Hadoop MapReduce</title>
        <link>https://canuxcheng.com/post/hadoop_mapreduce/</link>
        <pubDate>Wed, 03 May 2017 22:57:37 +0000</pubDate>
        
        <guid>https://canuxcheng.com/post/hadoop_mapreduce/</guid>
        <description>&lt;h1 id=&#34;map-reduce&#34;&gt;Map-Reduce&lt;/h1&gt;
&lt;p&gt;一种基于YARN的大型数据并行处理系统．主要处理离线数据．&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;mapreduce-commands&#34;&gt;mapreduce commands&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;mapred [SHELL_OPTIONS] COMMAND [GENERIC_OPTIONS] [COMMAND_OPTIONS]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;user commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ mapred archive
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;admin commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ mapred historyserver

$ mapred hsadmin
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>Hadoop</title>
        <link>https://canuxcheng.com/post/hadoop/</link>
        <pubDate>Mon, 11 Apr 2016 22:57:37 +0000</pubDate>
        
        <guid>https://canuxcheng.com/post/hadoop/</guid>
        <description>&lt;h1 id=&#34;hadoop&#34;&gt;Hadoop&lt;/h1&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/apache/hadoop&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/apache/hadoop&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;apache hadoop是一个框架，允许使用简单的编程模型在大量计算机上对大型数据集进行分布式处理．&lt;/p&gt;
&lt;p&gt;hadoop1只有HDFS和MapReduce两个模块，hadoop2开始分为HDFS, YARN, MapReduce三个模块．&lt;/p&gt;
&lt;p&gt;hadoop的版本:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;apache hadoop&lt;/li&gt;
&lt;li&gt;hortonworks hadoop (HDP)&lt;/li&gt;
&lt;li&gt;cloudera hadoop (CDH)&lt;/li&gt;
&lt;li&gt;mapr&lt;/li&gt;
&lt;li&gt;transwarp&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;安装hadoop&#34;&gt;安装hadoop&lt;/h1&gt;
&lt;p&gt;hadoop有三种安装模式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单节点模式&lt;/li&gt;
&lt;li&gt;伪分布式模式&lt;/li&gt;
&lt;li&gt;分布式模式&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考Linux Admin和Network SSH如何安装多台centos，并且配置局域网，让本地多台机器相互访问．&lt;/p&gt;
&lt;p&gt;下载hadoop的二进制安装包，然后放到/home/hadoop/目录下并解压．&lt;/p&gt;
&lt;p&gt;推荐的cluster node:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;NameNode(hdfs)
Secondary NameNode(hdfs)
DataNode(hdfs)
ResourceManager server(yarn)
NodeManager server(yarn)
WebAppProxy server(yarn)
MapReduceJobHistory server(mapreduce)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;设置环境变量：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ vim ~/.bash_profile
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-.../jre
export HADOOP_HOME=/home/hadoop/hadoop-3.0.0-alpha2
export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$PATH
$ source ~/.bash_profile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;修改hadoop的环境变量：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd hadoop-3.0.0-alpha2/etc/hadoop
$ vim hadoop-env.sh
export JAVA_HOME=&#39;/usr/lib/jvm/java-1.8.0-openjdk-.../jre

# 测试java和hadoop的环境是否可用：
$ hadoop
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;分布式环境搭建：&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/ClusterSetup.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/ClusterSetup.html&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ vim core-site.xml

$ vim hdfs-site.xml # namenode, datanode

$ vim yarn-site.xml # resourcemanager, nodemanager, webappproxy

$ vim mapred-site.xml # mr application, mr jobhistory

# slaves file
$ vim workers
namenode
secondnamenode
datanode
datanode2
yarnserver
mjhserver

# hadoop rack awareness

# logging
$ vim log4j.properties
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;CLI for hadoop cluster:&lt;/p&gt;
&lt;p&gt;启动一个hadoop　cluster需要同时启动hdfs和yarn, 推荐用单独的用户分别启动这两个组件．&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 第一次启动hdfs，需要格式化hdfs
$ hdfs namenode -format &amp;lt;cluster_name&amp;gt;

# 启动hdfs namenode 和　datanode
$ hdfs --daemon start namenode
$ hdfs --daemon start datanode
# 如果ssh已经实现无密码连接，可以一次启动cluster的所有node
$ $HADOOP_HOME/sbin/start-dfs.sh

# 启动yarn resourcemanager　和　nodemanager
$ yarn --daemon start resourcemanager
$ yarn --daemon start nodemanager
# 如果配置了slaves file 并且cluster node实现ssh无密码登陆，可以一次启动
$ $HADOOP_HOME/sbin/start-yarn.sh

# 启动webappproxy server
$ yarn --daemon start proxyserver

# 启动MapReduce Jobhistory server.
$ mapred --daemon start historyserver

# stop namenode
$ hdfs --daemon stop namenode
# stop datanode
$ hdfs --daemon stop datanode
# stop at the same time
$ $HADOOP_HOME/sbin/stop-dfs.sh

# stop resourcemanager
$ yarn --daemon stop resourcemanager
# stop nodemanager
$ yarn --daemon stop nodemanager
# stop at the same time
$ $HADOOP_HOME/sbin/stop-yarn.sh

# stop webappproxy server
$ yarn stop proxyserver

# stop jobhistory server
$ mapred --daemon stop historyserver
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;GUI for hadoop cluster:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# namenode
http://nn:9870
# resource manager
http:rm:8080
# mapreduce job history server
http://jhs:19888
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;hadoop-commands&#34;&gt;Hadoop Commands&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt; hadoop [--config confdir] [--loglevel loglevel] [COMMAND] [GENERIC_OPTIONS] [COMMAND_OPTIONS]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;user command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ hadoop archive
$ hadoop fs
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;admin command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ hadoop daemonlog
...
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;fs-commands&#34;&gt;fs commands&lt;/h1&gt;
&lt;p&gt;file system command:&lt;/p&gt;
&lt;p&gt;支持本地文件系统，hdfs文件系统，还有其它文件系统．&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ hadoop fs

$ hadoop fs -cat URI [URI ...]
...
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>Hadoop HDFS</title>
        <link>https://canuxcheng.com/post/hadoop_hdfs/</link>
        <pubDate>Mon, 11 Apr 2016 22:57:37 +0000</pubDate>
        
        <guid>https://canuxcheng.com/post/hadoop_hdfs/</guid>
        <description>&lt;h1 id=&#34;hdfs&#34;&gt;HDFS&lt;/h1&gt;
&lt;p&gt;Hadoop Distributed File System: hadoop分布式文件系统&lt;/p&gt;
&lt;p&gt;hadoop hdfs分为三部分:&lt;/p&gt;
&lt;p&gt;NameNode -&amp;gt; JobTracker&lt;/p&gt;
&lt;p&gt;secondary NameNode&lt;/p&gt;
&lt;p&gt;DataNode -&amp;gt; TaskTracker&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;hdfs-commands&#34;&gt;hdfs commands&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;hdfs [SHELL_OPTIONS] COMMAND [GENERIC_OPTIONS] [COMMAND_OPTIONS]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;user commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ hdfs classpath

$ hdfs dfs # 参考 hadoop fs命令
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;admin commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ hdfs balancer
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;debug commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ hdfs verify

$ hdfs recoverLease
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>Hadoop YARN</title>
        <link>https://canuxcheng.com/post/hadoop_yarn/</link>
        <pubDate>Mon, 11 Apr 2016 22:57:37 +0000</pubDate>
        
        <guid>https://canuxcheng.com/post/hadoop_yarn/</guid>
        <description>&lt;h1 id=&#34;yarn&#34;&gt;YARN&lt;/h1&gt;
&lt;p&gt;作业调度和集群资源管理的框架．&lt;/p&gt;
&lt;p&gt;yarn的两个组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;resourcemanager&lt;/li&gt;
&lt;li&gt;nodemanager&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&#34;yarn-commands&#34;&gt;yarn commands&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;yarn [--config confdir] COMMAND [--loglevel loglevel] [GENERIC_OPTIONS] [COMMAND_OPTIONS]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;user commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ yarn application
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;admin commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ yarn daemonlog
...
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;resource-manager&#34;&gt;resource manager&lt;/h1&gt;
&lt;p&gt;resource manager由两部分组成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;scheduler&lt;/li&gt;
&lt;li&gt;applicationmanager&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ResourceManager功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;处理客户请求&lt;/li&gt;
&lt;li&gt;启动／监控applicationmaster&lt;/li&gt;
&lt;li&gt;监控nodemanager&lt;/li&gt;
&lt;li&gt;资源分配与调度&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ApplicationMaster功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据切分&lt;/li&gt;
&lt;li&gt;为应用申请资源, 并分配给内部任务&lt;/li&gt;
&lt;li&gt;任务监控与容错&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&#34;node-manager&#34;&gt;node manager&lt;/h1&gt;
&lt;p&gt;node manager功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单个节点的资源管理&lt;/li&gt;
&lt;li&gt;处理来自resourcemanager的命令&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
        </item>
        
    </channel>
</rss>
