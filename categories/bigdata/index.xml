<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>BigData on Morgoth</title>
    <link>https://canuxcheng.com/categories/bigdata/</link>
    <description>Recent content in BigData on Morgoth</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 May 2017 22:57:37 +0000</lastBuildDate>
    <atom:link href="https://canuxcheng.com/categories/bigdata/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hadoop MapReduce</title>
      <link>https://canuxcheng.com/post/hadoop_mapreduce/</link>
      <pubDate>Wed, 03 May 2017 22:57:37 +0000</pubDate>
      <guid>https://canuxcheng.com/post/hadoop_mapreduce/</guid>
      <description>&lt;h1 id=&#34;map-reduce&#34;&gt;Map-Reduce&lt;/h1&gt;&#xA;&lt;p&gt;一种基于YARN的大型数据并行处理系统．主要处理离线数据．&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;mapreduce-commands&#34;&gt;mapreduce commands&lt;/h1&gt;&#xA;&lt;pre&gt;&lt;code&gt;mapred [SHELL_OPTIONS] COMMAND [GENERIC_OPTIONS] [COMMAND_OPTIONS]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;user commands:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ mapred archive&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;admin commands:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ mapred historyserver&#xA;&#xA;$ mapred hsadmin&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;hr&gt;</description>
    </item>
    <item>
      <title>HAWQ</title>
      <link>https://canuxcheng.com/post/hawq/</link>
      <pubDate>Mon, 24 Apr 2017 22:57:37 +0000</pubDate>
      <guid>https://canuxcheng.com/post/hawq/</guid>
      <description>&lt;h1 id=&#34;hawq&#34;&gt;HAWQ&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://hawq.incubator.apache.org/&#34;&gt;http://hawq.incubator.apache.org/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/apache/incubator-hawq&#34;&gt;https://github.com/apache/incubator-hawq&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;HAWQ是在Pivotal Greenplum和PostgreSQL基础上开发而来．&lt;/p&gt;&#xA;&lt;p&gt;HAWQ也就是Pivotal HDB.&lt;/p&gt;&#xA;&lt;p&gt;HAWQ和Pivotal　HDB是一个项目．&lt;/p&gt;&#xA;&lt;p&gt;Hortonworks公司的HDP集成了HAWQ.&lt;/p&gt;&#xA;&lt;p&gt;HAWQ可以通过HDFS在本机快速，交互查询hadoop数据．&lt;/p&gt;&#xA;&lt;p&gt;hawq的交互式命令行接口, 类似于postgresql, 参考postgresql.&lt;/p&gt;&#xA;&lt;p&gt;hawq的client: psql (参考postgresql)&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;psql&#34;&gt;psql&lt;/h1&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ psql&#xA;$ PGPASSWORD=&#39;password&#39;;psql -h &amp;lt;host&amp;gt; -p &amp;lt;port&amp;gt; -U &amp;lt;username&amp;gt; -d [database] -c &amp;quot;[psql command]&amp;quot;&#xA;$ psql -l # 查看所有database&#xA;&#xA;# jdbc&#xA;$ jdbc:pivotal:greenplum://hdm1:5432;DatabaseName=getstartdb;User=hdbuser;Password=hdbpass&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;sql&#34;&gt;sql&lt;/h1&gt;&#xA;&lt;p&gt;AO(append only) table:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type1);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;parquet table:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type2) WITH (appendonly=true, orientation=parquet);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;AO table distributed by specified column and partitioned by range:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hive</title>
      <link>https://canuxcheng.com/post/hive/</link>
      <pubDate>Mon, 24 Apr 2017 22:57:37 +0000</pubDate>
      <guid>https://canuxcheng.com/post/hive/</guid>
      <description>&lt;h1 id=&#34;hive&#34;&gt;Hive&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/apache/hive&#34;&gt;https://github.com/apache/hive&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://hive.apache.org/&#34;&gt;http://hive.apache.org/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Hive2数据仓库用于读取，写入和管理使用SQL的大型分布式数据集．&lt;/p&gt;&#xA;&lt;p&gt;hive2的client: beeline(hive命令的升级版)&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;hivebeeline&#34;&gt;hive/beeline&lt;/h1&gt;&#xA;&lt;p&gt;hive&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ hive --help&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;beeline&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ beeline --silent=true&#xA;beeline&amp;gt; !connect jdbc:hive2://[ip]:[port]/[database] [username] [password]&#xA;&#xA;$ beeline -u &amp;quot;jdbc:hive2://[ip]:10000[/database]&amp;quot; -n [username] -p [password] -e &amp;quot;USE [database]; ...&amp;quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;sql&#34;&gt;sql&lt;/h1&gt;&#xA;&lt;p&gt;normal table:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; create table tablename (var type, var1 type1);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;parquet table:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type1) STORED AS PARQUET;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;partition table:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type1) PARTITION BY (var2 type2);&#xA;&amp;gt; insert into {table_name} PARTITION (var2 = {pid}) VALUES {values};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;parquet partition table:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Impala</title>
      <link>https://canuxcheng.com/post/impala/</link>
      <pubDate>Mon, 24 Apr 2017 22:57:37 +0000</pubDate>
      <guid>https://canuxcheng.com/post/impala/</guid>
      <description>&lt;h1 id=&#34;impala&#34;&gt;Impala&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/apache/incubator-impala&#34;&gt;https://github.com/apache/incubator-impala&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://impala.apache.org/&#34;&gt;https://impala.apache.org/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;impala的client: impala-shell&lt;/p&gt;&#xA;&lt;p&gt;Cloudera公司的CDH集成了Impala.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;impala-shellbeeline&#34;&gt;impala-shell/beeline&lt;/h1&gt;&#xA;&lt;p&gt;impala-shell&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ impala-shell&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;beeline&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ beeline --silent=true&#xA;beeline&amp;gt; !connect jdbc:hive2://[ip]:21050[/database];auth=noSasl [username] [password]&#xA;&#xA;$ beeline -u &amp;quot;jdbc:hive2://[ip]:21050[/database];auth=noSasl&amp;quot; -n [username] -p [password] -e &amp;quot;USE [database]; ...&amp;quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;sql&#34;&gt;sql&lt;/h1&gt;&#xA;&lt;p&gt;normal table:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type1);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;parquet table:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; crate table {table_name} (var type, var1 type1) STORED AS PARQUET;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;partition table:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type1) PARTITIONED BY (var2 type2);&#xA;&amp;gt; insert into {table_name} PARTITION (var2 = val2) values (val, val1)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;parquet partition table:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Presto</title>
      <link>https://canuxcheng.com/post/presto/</link>
      <pubDate>Mon, 24 Apr 2017 22:57:37 +0000</pubDate>
      <guid>https://canuxcheng.com/post/presto/</guid>
      <description>&lt;h1 id=&#34;presto&#34;&gt;Presto&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/prestodb&#34;&gt;https://github.com/prestodb&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://prestodb.io/&#34;&gt;https://prestodb.io/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;presto的client: presto-cli(rename to presto)&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;presto-cli&#34;&gt;presto-cli&lt;/h1&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ presto --server localhost:8080 --catalog hive --schema default&#xA;&#xA;# jdbc for presto&#xA;$ jdbc:presto://host:port/catalog/schema&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>Hadoop</title>
      <link>https://canuxcheng.com/post/hadoop/</link>
      <pubDate>Mon, 11 Apr 2016 22:57:37 +0000</pubDate>
      <guid>https://canuxcheng.com/post/hadoop/</guid>
      <description>&lt;h1 id=&#34;hadoop&#34;&gt;Hadoop&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/apache/hadoop&#34;&gt;https://github.com/apache/hadoop&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;apache hadoop是一个框架，允许使用简单的编程模型在大量计算机上对大型数据集进行分布式处理．&lt;/p&gt;&#xA;&lt;p&gt;hadoop1只有HDFS和MapReduce两个模块，hadoop2开始分为HDFS, YARN, MapReduce三个模块．&lt;/p&gt;&#xA;&lt;p&gt;hadoop的版本:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;apache hadoop&lt;/li&gt;&#xA;&lt;li&gt;hortonworks hadoop (HDP)&lt;/li&gt;&#xA;&lt;li&gt;cloudera hadoop (CDH)&lt;/li&gt;&#xA;&lt;li&gt;mapr&lt;/li&gt;&#xA;&lt;li&gt;transwarp&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;安装hadoop&#34;&gt;安装hadoop&lt;/h1&gt;&#xA;&lt;p&gt;hadoop有三种安装模式：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;单节点模式&lt;/li&gt;&#xA;&lt;li&gt;伪分布式模式&lt;/li&gt;&#xA;&lt;li&gt;分布式模式&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;参考Linux Admin和Network SSH如何安装多台centos，并且配置局域网，让本地多台机器相互访问．&lt;/p&gt;&#xA;&lt;p&gt;下载hadoop的二进制安装包，然后放到/home/hadoop/目录下并解压．&lt;/p&gt;&#xA;&lt;p&gt;推荐的cluster node:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;NameNode(hdfs)&#xA;Secondary NameNode(hdfs)&#xA;DataNode(hdfs)&#xA;ResourceManager server(yarn)&#xA;NodeManager server(yarn)&#xA;WebAppProxy server(yarn)&#xA;MapReduceJobHistory server(mapreduce)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;设置环境变量：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ vim ~/.bash_profile&#xA;export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-.../jre&#xA;export HADOOP_HOME=/home/hadoop/hadoop-3.0.0-alpha2&#xA;export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$PATH&#xA;$ source ~/.bash_profile&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;修改hadoop的环境变量：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ cd hadoop-3.0.0-alpha2/etc/hadoop&#xA;$ vim hadoop-env.sh&#xA;export JAVA_HOME=&#39;/usr/lib/jvm/java-1.8.0-openjdk-.../jre&#xA;&#xA;# 测试java和hadoop的环境是否可用：&#xA;$ hadoop&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;分布式环境搭建：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hadoop HDFS</title>
      <link>https://canuxcheng.com/post/hadoop_hdfs/</link>
      <pubDate>Mon, 11 Apr 2016 22:57:37 +0000</pubDate>
      <guid>https://canuxcheng.com/post/hadoop_hdfs/</guid>
      <description>&lt;h1 id=&#34;hdfs&#34;&gt;HDFS&lt;/h1&gt;&#xA;&lt;p&gt;Hadoop Distributed File System: hadoop分布式文件系统&lt;/p&gt;&#xA;&lt;p&gt;hadoop hdfs分为三部分:&lt;/p&gt;&#xA;&lt;p&gt;NameNode -&amp;gt; JobTracker&lt;/p&gt;&#xA;&lt;p&gt;secondary NameNode&lt;/p&gt;&#xA;&lt;p&gt;DataNode -&amp;gt; TaskTracker&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;hdfs-commands&#34;&gt;hdfs commands&lt;/h1&gt;&#xA;&lt;pre&gt;&lt;code&gt;hdfs [SHELL_OPTIONS] COMMAND [GENERIC_OPTIONS] [COMMAND_OPTIONS]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;user commands:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ hdfs classpath&#xA;&#xA;$ hdfs dfs # 参考 hadoop fs命令&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;admin commands:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ hdfs balancer&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;debug commands:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ hdfs verify&#xA;&#xA;$ hdfs recoverLease&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;hr&gt;</description>
    </item>
    <item>
      <title>Hadoop YARN</title>
      <link>https://canuxcheng.com/post/hadoop_yarn/</link>
      <pubDate>Mon, 11 Apr 2016 22:57:37 +0000</pubDate>
      <guid>https://canuxcheng.com/post/hadoop_yarn/</guid>
      <description>&lt;h1 id=&#34;yarn&#34;&gt;YARN&lt;/h1&gt;&#xA;&lt;p&gt;作业调度和集群资源管理的框架．&lt;/p&gt;&#xA;&lt;p&gt;yarn的两个组件：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;resourcemanager&lt;/li&gt;&#xA;&lt;li&gt;nodemanager&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;yarn-commands&#34;&gt;yarn commands&lt;/h1&gt;&#xA;&lt;pre&gt;&lt;code&gt;yarn [--config confdir] COMMAND [--loglevel loglevel] [GENERIC_OPTIONS] [COMMAND_OPTIONS]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;user commands:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ yarn application&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;admin commands:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ yarn daemonlog&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;resource-manager&#34;&gt;resource manager&lt;/h1&gt;&#xA;&lt;p&gt;resource manager由两部分组成：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;scheduler&lt;/li&gt;&#xA;&lt;li&gt;applicationmanager&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;ResourceManager功能：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;处理客户请求&lt;/li&gt;&#xA;&lt;li&gt;启动／监控applicationmaster&lt;/li&gt;&#xA;&lt;li&gt;监控nodemanager&lt;/li&gt;&#xA;&lt;li&gt;资源分配与调度&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;ApplicationMaster功能：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;数据切分&lt;/li&gt;&#xA;&lt;li&gt;为应用申请资源, 并分配给内部任务&lt;/li&gt;&#xA;&lt;li&gt;任务监控与容错&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;node-manager&#34;&gt;node manager&lt;/h1&gt;&#xA;&lt;p&gt;node manager功能：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;单个节点的资源管理&lt;/li&gt;&#xA;&lt;li&gt;处理来自resourcemanager的命令&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;</description>
    </item>
    <item>
      <title>BigData</title>
      <link>https://canuxcheng.com/post/bigdata/</link>
      <pubDate>Mon, 11 Apr 2016 22:57:37 +0800</pubDate>
      <guid>https://canuxcheng.com/post/bigdata/</guid>
      <description>&lt;h1 id=&#34;bigdata&#34;&gt;BigData&lt;/h1&gt;&#xA;&lt;p&gt;大数据最流行的框架是hadoop.&lt;/p&gt;&#xA;&lt;p&gt;大部分工具都属于Apache基金会的项目．&lt;/p&gt;&#xA;&lt;h1 id=&#34;mpp&#34;&gt;MPP&lt;/h1&gt;&#xA;&lt;p&gt;Massive Parallel Process&lt;/p&gt;&#xA;&lt;p&gt;大规模并行处理数据库包括impala, hawq&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;分布式存储&#34;&gt;分布式存储&lt;/h1&gt;&#xA;&lt;h2 id=&#34;hadoop-hdfs&#34;&gt;hadoop hdfs&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;资源调度&#34;&gt;资源调度&lt;/h1&gt;&#xA;&lt;h2 id=&#34;hadoop-yarn&#34;&gt;hadoop yarn&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;分布式计算框架&#34;&gt;分布式计算框架&lt;/h1&gt;&#xA;&lt;h2 id=&#34;hadoop-mapreduce&#34;&gt;hadoop mapreduce&lt;/h2&gt;&#xA;&lt;h2 id=&#34;spark&#34;&gt;Spark&lt;/h2&gt;&#xA;&lt;h1 id=&#34;流式计算框架&#34;&gt;流式计算框架&lt;/h1&gt;&#xA;&lt;h2 id=&#34;storm&#34;&gt;Storm&lt;/h2&gt;&#xA;&lt;h2 id=&#34;flink&#34;&gt;Flink&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;部署工具&#34;&gt;部署工具&lt;/h1&gt;&#xA;&lt;h2 id=&#34;ambari&#34;&gt;Ambari&lt;/h2&gt;&#xA;&lt;p&gt;用于配置，管理，监控hadoop集群的web工具．&lt;/p&gt;&#xA;&lt;h2 id=&#34;bigtop&#34;&gt;Bigtop&lt;/h2&gt;&#xA;&lt;p&gt;对hadoop相关软件打包，分发，测试的工具．&lt;/p&gt;&#xA;&lt;h2 id=&#34;whirr&#34;&gt;whirr&lt;/h2&gt;&#xA;&lt;h2 id=&#34;cloudera-hue&#34;&gt;Cloudera Hue&lt;/h2&gt;&#xA;&lt;h2 id=&#34;hortonworks-hoya&#34;&gt;Hortonworks hoya&lt;/h2&gt;&#xA;&lt;h1 id=&#34;服务编程&#34;&gt;服务编程&lt;/h1&gt;&#xA;&lt;h2 id=&#34;zookeeper&#34;&gt;Zookeeper&lt;/h2&gt;&#xA;&lt;p&gt;分布式应用程序的高性能协调服务&lt;/p&gt;&#xA;&lt;h2 id=&#34;curator&#34;&gt;Curator&lt;/h2&gt;&#xA;&lt;h2 id=&#34;avro&#34;&gt;Avro&lt;/h2&gt;&#xA;&lt;h2 id=&#34;chuckwa&#34;&gt;chuckwa&lt;/h2&gt;&#xA;&lt;p&gt;用于监控大型分布式系统的数据收集系统．&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;交互式分析框架sql-on-hadoop&#34;&gt;交互式分析框架(Sql On Hadoop)&lt;/h1&gt;&#xA;&lt;h2 id=&#34;facebook-presto&#34;&gt;Facebook Presto&lt;/h2&gt;&#xA;&lt;h2 id=&#34;hive&#34;&gt;Hive&lt;/h2&gt;&#xA;&lt;h2 id=&#34;hawqpivotal&#34;&gt;Hawq(Pivotal)&lt;/h2&gt;&#xA;&lt;p&gt;Hortonworks的HDP集成了HAWQ.&lt;/p&gt;&#xA;&lt;h2 id=&#34;impalacloudera&#34;&gt;Impala(Cloudera)&lt;/h2&gt;&#xA;&lt;p&gt;Cloudera的CHD集成了Impala.&lt;/p&gt;&#xA;&lt;h1 id=&#34;交互式分析框架nosql-on-hadoop&#34;&gt;交互式分析框架(NoSQL On Hadoop)&lt;/h1&gt;&#xA;&lt;h2 id=&#34;hbase&#34;&gt;HBase&lt;/h2&gt;&#xA;&lt;h2 id=&#34;cassandra&#34;&gt;Cassandra&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;数据管理工具&#34;&gt;数据管理工具&lt;/h1&gt;&#xA;&lt;h2 id=&#34;sqoop&#34;&gt;Sqoop&lt;/h2&gt;&#xA;&lt;h2 id=&#34;flume&#34;&gt;Flume&lt;/h2&gt;&#xA;&lt;h1 id=&#34;消息队列&#34;&gt;消息队列&lt;/h1&gt;&#xA;&lt;h2 id=&#34;kafka&#34;&gt;Kafka&lt;/h2&gt;&#xA;&lt;h2 id=&#34;pivotal-rabbitmq&#34;&gt;Pivotal RabbitMQ&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;dsl&#34;&gt;DSL&lt;/h1&gt;&#xA;&lt;h2 id=&#34;pig&#34;&gt;Pig&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;workflow-and-lifecycle&#34;&gt;Workflow and Lifecycle&lt;/h1&gt;&#xA;&lt;h2 id=&#34;oozie&#34;&gt;Oozie&lt;/h2&gt;&#xA;&lt;h2 id=&#34;aurora&#34;&gt;aurora&lt;/h2&gt;&#xA;&lt;h2 id=&#34;falcon&#34;&gt;falcon&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;security&#34;&gt;Security&lt;/h1&gt;&#xA;&lt;h2 id=&#34;sentry&#34;&gt;Sentry&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;data-search&#34;&gt;Data search&lt;/h1&gt;&#xA;&lt;h2 id=&#34;solr&#34;&gt;Solr&lt;/h2&gt;&#xA;&lt;h2 id=&#34;nutch&#34;&gt;Nutch&lt;/h2&gt;&#xA;&lt;h2 id=&#34;lucene&#34;&gt;Lucene&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;data-analytics&#34;&gt;Data Analytics&lt;/h1&gt;&#xA;&lt;h2 id=&#34;mahout&#34;&gt;Mahout&lt;/h2&gt;&#xA;&lt;h2 id=&#34;kuducloudera&#34;&gt;Kudu(Cloudera)&lt;/h2&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;misc&#34;&gt;Misc&lt;/h1&gt;&#xA;&lt;h2 id=&#34;hama&#34;&gt;hama&lt;/h2&gt;&#xA;&lt;h2 id=&#34;giraph&#34;&gt;giraph&lt;/h2&gt;&#xA;&lt;h2 id=&#34;crunch&#34;&gt;crunch&lt;/h2&gt;&#xA;&lt;h2 id=&#34;hcatalog&#34;&gt;hcatalog&lt;/h2&gt;</description>
    </item>
  </channel>
</rss>
