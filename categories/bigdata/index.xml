<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>BigData on Morgoth</title>
        <link>https://canuxcheng.com/categories/bigdata/</link>
        <description>Recent content in BigData on Morgoth</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Wed, 03 May 2017 22:57:37 +0000</lastBuildDate><atom:link href="https://canuxcheng.com/categories/bigdata/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Hadoop MapReduce</title>
        <link>https://canuxcheng.com/post/hadoop_mapreduce/</link>
        <pubDate>Wed, 03 May 2017 22:57:37 +0000</pubDate>
        
        <guid>https://canuxcheng.com/post/hadoop_mapreduce/</guid>
        <description>&lt;h1 id=&#34;map-reduce&#34;&gt;Map-Reduce&lt;/h1&gt;
&lt;p&gt;一种基于YARN的大型数据并行处理系统．主要处理离线数据．&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;mapreduce-commands&#34;&gt;mapreduce commands&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;mapred [SHELL_OPTIONS] COMMAND [GENERIC_OPTIONS] [COMMAND_OPTIONS]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;user commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ mapred archive
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;admin commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ mapred historyserver

$ mapred hsadmin
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>HAWQ</title>
        <link>https://canuxcheng.com/post/hawq/</link>
        <pubDate>Mon, 24 Apr 2017 22:57:37 +0000</pubDate>
        
        <guid>https://canuxcheng.com/post/hawq/</guid>
        <description>&lt;h1 id=&#34;hawq&#34;&gt;HAWQ&lt;/h1&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://hawq.incubator.apache.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://hawq.incubator.apache.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/apache/incubator-hawq&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/apache/incubator-hawq&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;HAWQ是在Pivotal Greenplum和PostgreSQL基础上开发而来．&lt;/p&gt;
&lt;p&gt;HAWQ也就是Pivotal HDB.&lt;/p&gt;
&lt;p&gt;HAWQ和Pivotal　HDB是一个项目．&lt;/p&gt;
&lt;p&gt;Hortonworks公司的HDP集成了HAWQ.&lt;/p&gt;
&lt;p&gt;HAWQ可以通过HDFS在本机快速，交互查询hadoop数据．&lt;/p&gt;
&lt;p&gt;hawq的交互式命令行接口, 类似于postgresql, 参考postgresql.&lt;/p&gt;
&lt;p&gt;hawq的client: psql (参考postgresql)&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;psql&#34;&gt;psql&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;$ psql
$ PGPASSWORD=&#39;password&#39;;psql -h &amp;lt;host&amp;gt; -p &amp;lt;port&amp;gt; -U &amp;lt;username&amp;gt; -d [database] -c &amp;quot;[psql command]&amp;quot;
$ psql -l # 查看所有database

# jdbc
$ jdbc:pivotal:greenplum://hdm1:5432;DatabaseName=getstartdb;User=hdbuser;Password=hdbpass
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;sql&#34;&gt;sql&lt;/h1&gt;
&lt;p&gt;AO(append only) table:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type1);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;parquet table:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type2) WITH (appendonly=true, orientation=parquet);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;AO table distributed by specified column and partitioned by range:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type1) distributed by range(var) partition by range(var1) (start val end val1 every val2);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;AO table distributed by randomly and partitioned by range:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type1) distributed randomly partition by range (var) (start(val) end (val1) every(val2));
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;parquet table distributed by specified column and partitoned by list:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type1) WITH (appendonly=true, orientation=parquet) distributed by (var) partition by list (var1) (partition name values (val), partition name1 values (val1));
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;parquet table distributed by randomly and partitioned by list:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type1) WITH (appendonly=true, orientation=parquet) distributed randomly partiton by list (var1) (partition name values (val), partition name1 values (val));
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Hive</title>
        <link>https://canuxcheng.com/post/hive/</link>
        <pubDate>Mon, 24 Apr 2017 22:57:37 +0000</pubDate>
        
        <guid>https://canuxcheng.com/post/hive/</guid>
        <description>&lt;h1 id=&#34;hive&#34;&gt;Hive&lt;/h1&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/apache/hive&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/apache/hive&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://hive.apache.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://hive.apache.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hive2数据仓库用于读取，写入和管理使用SQL的大型分布式数据集．&lt;/p&gt;
&lt;p&gt;hive2的client: beeline(hive命令的升级版)&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;hivebeeline&#34;&gt;hive/beeline&lt;/h1&gt;
&lt;p&gt;hive&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ hive --help
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;beeline&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ beeline --silent=true
beeline&amp;gt; !connect jdbc:hive2://[ip]:[port]/[database] [username] [password]

$ beeline -u &amp;quot;jdbc:hive2://[ip]:10000[/database]&amp;quot; -n [username] -p [password] -e &amp;quot;USE [database]; ...&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;sql&#34;&gt;sql&lt;/h1&gt;
&lt;p&gt;normal table:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; create table tablename (var type, var1 type1);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;parquet table:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type1) STORED AS PARQUET;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;partition table:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type1) PARTITION BY (var2 type2);
&amp;gt; insert into {table_name} PARTITION (var2 = {pid}) VALUES {values};
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;parquet partition table:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type1) PARTITIONED BY (var2 type2) STORED AS PARQUET;
&amp;gt; insert into {table_name} PARTITION (var2 = {pid}) VALUES {values};
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Impala</title>
        <link>https://canuxcheng.com/post/impala/</link>
        <pubDate>Mon, 24 Apr 2017 22:57:37 +0000</pubDate>
        
        <guid>https://canuxcheng.com/post/impala/</guid>
        <description>&lt;h1 id=&#34;impala&#34;&gt;Impala&lt;/h1&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/apache/incubator-impala&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/apache/incubator-impala&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://impala.apache.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://impala.apache.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;impala的client: impala-shell&lt;/p&gt;
&lt;p&gt;Cloudera公司的CDH集成了Impala.&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;impala-shellbeeline&#34;&gt;impala-shell/beeline&lt;/h1&gt;
&lt;p&gt;impala-shell&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ impala-shell
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;beeline&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ beeline --silent=true
beeline&amp;gt; !connect jdbc:hive2://[ip]:21050[/database];auth=noSasl [username] [password]

$ beeline -u &amp;quot;jdbc:hive2://[ip]:21050[/database];auth=noSasl&amp;quot; -n [username] -p [password] -e &amp;quot;USE [database]; ...&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;sql&#34;&gt;sql&lt;/h1&gt;
&lt;p&gt;normal table:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type1);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;parquet table:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; crate table {table_name} (var type, var1 type1) STORED AS PARQUET;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;partition table:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type1) PARTITIONED BY (var2 type2);
&amp;gt; insert into {table_name} PARTITION (var2 = val2) values (val, val1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;parquet partition table:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; create table {table_name} (var type, var1 type1) PARTITION BY (var2 type2) STORED AS PARQUET;
&amp;gt; insert into {table_name} PARTITION (var2 = val2) values (val, val1)
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Presto</title>
        <link>https://canuxcheng.com/post/presto/</link>
        <pubDate>Mon, 24 Apr 2017 22:57:37 +0000</pubDate>
        
        <guid>https://canuxcheng.com/post/presto/</guid>
        <description>&lt;h1 id=&#34;presto&#34;&gt;Presto&lt;/h1&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/prestodb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/prestodb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://prestodb.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://prestodb.io/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;presto的client: presto-cli(rename to presto)&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;presto-cli&#34;&gt;presto-cli&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;$ presto --server localhost:8080 --catalog hive --schema default

# jdbc for presto
$ jdbc:presto://host:port/catalog/schema
&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>Hadoop</title>
        <link>https://canuxcheng.com/post/hadoop/</link>
        <pubDate>Mon, 11 Apr 2016 22:57:37 +0000</pubDate>
        
        <guid>https://canuxcheng.com/post/hadoop/</guid>
        <description>&lt;h1 id=&#34;hadoop&#34;&gt;Hadoop&lt;/h1&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/apache/hadoop&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/apache/hadoop&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;apache hadoop是一个框架，允许使用简单的编程模型在大量计算机上对大型数据集进行分布式处理．&lt;/p&gt;
&lt;p&gt;hadoop1只有HDFS和MapReduce两个模块，hadoop2开始分为HDFS, YARN, MapReduce三个模块．&lt;/p&gt;
&lt;p&gt;hadoop的版本:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;apache hadoop&lt;/li&gt;
&lt;li&gt;hortonworks hadoop (HDP)&lt;/li&gt;
&lt;li&gt;cloudera hadoop (CDH)&lt;/li&gt;
&lt;li&gt;mapr&lt;/li&gt;
&lt;li&gt;transwarp&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;安装hadoop&#34;&gt;安装hadoop&lt;/h1&gt;
&lt;p&gt;hadoop有三种安装模式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单节点模式&lt;/li&gt;
&lt;li&gt;伪分布式模式&lt;/li&gt;
&lt;li&gt;分布式模式&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考Linux Admin和Network SSH如何安装多台centos，并且配置局域网，让本地多台机器相互访问．&lt;/p&gt;
&lt;p&gt;下载hadoop的二进制安装包，然后放到/home/hadoop/目录下并解压．&lt;/p&gt;
&lt;p&gt;推荐的cluster node:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;NameNode(hdfs)
Secondary NameNode(hdfs)
DataNode(hdfs)
ResourceManager server(yarn)
NodeManager server(yarn)
WebAppProxy server(yarn)
MapReduceJobHistory server(mapreduce)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;设置环境变量：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ vim ~/.bash_profile
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-.../jre
export HADOOP_HOME=/home/hadoop/hadoop-3.0.0-alpha2
export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$PATH
$ source ~/.bash_profile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;修改hadoop的环境变量：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd hadoop-3.0.0-alpha2/etc/hadoop
$ vim hadoop-env.sh
export JAVA_HOME=&#39;/usr/lib/jvm/java-1.8.0-openjdk-.../jre

# 测试java和hadoop的环境是否可用：
$ hadoop
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;分布式环境搭建：&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/ClusterSetup.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/ClusterSetup.html&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ vim core-site.xml

$ vim hdfs-site.xml # namenode, datanode

$ vim yarn-site.xml # resourcemanager, nodemanager, webappproxy

$ vim mapred-site.xml # mr application, mr jobhistory

# slaves file
$ vim workers
namenode
secondnamenode
datanode
datanode2
yarnserver
mjhserver

# hadoop rack awareness

# logging
$ vim log4j.properties
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;CLI for hadoop cluster:&lt;/p&gt;
&lt;p&gt;启动一个hadoop　cluster需要同时启动hdfs和yarn, 推荐用单独的用户分别启动这两个组件．&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 第一次启动hdfs，需要格式化hdfs
$ hdfs namenode -format &amp;lt;cluster_name&amp;gt;

# 启动hdfs namenode 和　datanode
$ hdfs --daemon start namenode
$ hdfs --daemon start datanode
# 如果ssh已经实现无密码连接，可以一次启动cluster的所有node
$ $HADOOP_HOME/sbin/start-dfs.sh

# 启动yarn resourcemanager　和　nodemanager
$ yarn --daemon start resourcemanager
$ yarn --daemon start nodemanager
# 如果配置了slaves file 并且cluster node实现ssh无密码登陆，可以一次启动
$ $HADOOP_HOME/sbin/start-yarn.sh

# 启动webappproxy server
$ yarn --daemon start proxyserver

# 启动MapReduce Jobhistory server.
$ mapred --daemon start historyserver

# stop namenode
$ hdfs --daemon stop namenode
# stop datanode
$ hdfs --daemon stop datanode
# stop at the same time
$ $HADOOP_HOME/sbin/stop-dfs.sh

# stop resourcemanager
$ yarn --daemon stop resourcemanager
# stop nodemanager
$ yarn --daemon stop nodemanager
# stop at the same time
$ $HADOOP_HOME/sbin/stop-yarn.sh

# stop webappproxy server
$ yarn stop proxyserver

# stop jobhistory server
$ mapred --daemon stop historyserver
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;GUI for hadoop cluster:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# namenode
http://nn:9870
# resource manager
http:rm:8080
# mapreduce job history server
http://jhs:19888
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;hadoop-commands&#34;&gt;Hadoop Commands&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt; hadoop [--config confdir] [--loglevel loglevel] [COMMAND] [GENERIC_OPTIONS] [COMMAND_OPTIONS]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;user command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ hadoop archive
$ hadoop fs
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;admin command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ hadoop daemonlog
...
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;fs-commands&#34;&gt;fs commands&lt;/h1&gt;
&lt;p&gt;file system command:&lt;/p&gt;
&lt;p&gt;支持本地文件系统，hdfs文件系统，还有其它文件系统．&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ hadoop fs

$ hadoop fs -cat URI [URI ...]
...
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>Hadoop HDFS</title>
        <link>https://canuxcheng.com/post/hadoop_hdfs/</link>
        <pubDate>Mon, 11 Apr 2016 22:57:37 +0000</pubDate>
        
        <guid>https://canuxcheng.com/post/hadoop_hdfs/</guid>
        <description>&lt;h1 id=&#34;hdfs&#34;&gt;HDFS&lt;/h1&gt;
&lt;p&gt;Hadoop Distributed File System: hadoop分布式文件系统&lt;/p&gt;
&lt;p&gt;hadoop hdfs分为三部分:&lt;/p&gt;
&lt;p&gt;NameNode -&amp;gt; JobTracker&lt;/p&gt;
&lt;p&gt;secondary NameNode&lt;/p&gt;
&lt;p&gt;DataNode -&amp;gt; TaskTracker&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;hdfs-commands&#34;&gt;hdfs commands&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;hdfs [SHELL_OPTIONS] COMMAND [GENERIC_OPTIONS] [COMMAND_OPTIONS]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;user commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ hdfs classpath

$ hdfs dfs # 参考 hadoop fs命令
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;admin commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ hdfs balancer
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;debug commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ hdfs verify

$ hdfs recoverLease
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>Hadoop YARN</title>
        <link>https://canuxcheng.com/post/hadoop_yarn/</link>
        <pubDate>Mon, 11 Apr 2016 22:57:37 +0000</pubDate>
        
        <guid>https://canuxcheng.com/post/hadoop_yarn/</guid>
        <description>&lt;h1 id=&#34;yarn&#34;&gt;YARN&lt;/h1&gt;
&lt;p&gt;作业调度和集群资源管理的框架．&lt;/p&gt;
&lt;p&gt;yarn的两个组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;resourcemanager&lt;/li&gt;
&lt;li&gt;nodemanager&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&#34;yarn-commands&#34;&gt;yarn commands&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;yarn [--config confdir] COMMAND [--loglevel loglevel] [GENERIC_OPTIONS] [COMMAND_OPTIONS]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;user commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ yarn application
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;admin commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ yarn daemonlog
...
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;resource-manager&#34;&gt;resource manager&lt;/h1&gt;
&lt;p&gt;resource manager由两部分组成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;scheduler&lt;/li&gt;
&lt;li&gt;applicationmanager&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ResourceManager功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;处理客户请求&lt;/li&gt;
&lt;li&gt;启动／监控applicationmaster&lt;/li&gt;
&lt;li&gt;监控nodemanager&lt;/li&gt;
&lt;li&gt;资源分配与调度&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ApplicationMaster功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据切分&lt;/li&gt;
&lt;li&gt;为应用申请资源, 并分配给内部任务&lt;/li&gt;
&lt;li&gt;任务监控与容错&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&#34;node-manager&#34;&gt;node manager&lt;/h1&gt;
&lt;p&gt;node manager功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单个节点的资源管理&lt;/li&gt;
&lt;li&gt;处理来自resourcemanager的命令&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>BigData</title>
        <link>https://canuxcheng.com/post/bigdata/</link>
        <pubDate>Mon, 11 Apr 2016 22:57:37 +0800</pubDate>
        
        <guid>https://canuxcheng.com/post/bigdata/</guid>
        <description>&lt;h1 id=&#34;bigdata&#34;&gt;BigData&lt;/h1&gt;
&lt;p&gt;大数据最流行的框架是hadoop.&lt;/p&gt;
&lt;p&gt;大部分工具都属于Apache基金会的项目．&lt;/p&gt;
&lt;h1 id=&#34;mpp&#34;&gt;MPP&lt;/h1&gt;
&lt;p&gt;Massive Parallel Process&lt;/p&gt;
&lt;p&gt;大规模并行处理数据库包括impala, hawq&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;分布式存储&#34;&gt;分布式存储&lt;/h1&gt;
&lt;h2 id=&#34;hadoop-hdfs&#34;&gt;hadoop hdfs&lt;/h2&gt;
&lt;hr&gt;
&lt;h1 id=&#34;资源调度&#34;&gt;资源调度&lt;/h1&gt;
&lt;h2 id=&#34;hadoop-yarn&#34;&gt;hadoop yarn&lt;/h2&gt;
&lt;hr&gt;
&lt;h1 id=&#34;分布式计算框架&#34;&gt;分布式计算框架&lt;/h1&gt;
&lt;h2 id=&#34;hadoop-mapreduce&#34;&gt;hadoop mapreduce&lt;/h2&gt;
&lt;h2 id=&#34;spark&#34;&gt;Spark&lt;/h2&gt;
&lt;h1 id=&#34;流式计算框架&#34;&gt;流式计算框架&lt;/h1&gt;
&lt;h2 id=&#34;storm&#34;&gt;Storm&lt;/h2&gt;
&lt;h2 id=&#34;flink&#34;&gt;Flink&lt;/h2&gt;
&lt;hr&gt;
&lt;h1 id=&#34;部署工具&#34;&gt;部署工具&lt;/h1&gt;
&lt;h2 id=&#34;ambari&#34;&gt;Ambari&lt;/h2&gt;
&lt;p&gt;用于配置，管理，监控hadoop集群的web工具．&lt;/p&gt;
&lt;h2 id=&#34;bigtop&#34;&gt;Bigtop&lt;/h2&gt;
&lt;p&gt;对hadoop相关软件打包，分发，测试的工具．&lt;/p&gt;
&lt;h2 id=&#34;whirr&#34;&gt;whirr&lt;/h2&gt;
&lt;h2 id=&#34;cloudera-hue&#34;&gt;Cloudera Hue&lt;/h2&gt;
&lt;h2 id=&#34;hortonworks-hoya&#34;&gt;Hortonworks hoya&lt;/h2&gt;
&lt;h1 id=&#34;服务编程&#34;&gt;服务编程&lt;/h1&gt;
&lt;h2 id=&#34;zookeeper&#34;&gt;Zookeeper&lt;/h2&gt;
&lt;p&gt;分布式应用程序的高性能协调服务&lt;/p&gt;
&lt;h2 id=&#34;curator&#34;&gt;Curator&lt;/h2&gt;
&lt;h2 id=&#34;avro&#34;&gt;Avro&lt;/h2&gt;
&lt;h2 id=&#34;chuckwa&#34;&gt;chuckwa&lt;/h2&gt;
&lt;p&gt;用于监控大型分布式系统的数据收集系统．&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;交互式分析框架sql-on-hadoop&#34;&gt;交互式分析框架(Sql On Hadoop)&lt;/h1&gt;
&lt;h2 id=&#34;facebook-presto&#34;&gt;Facebook Presto&lt;/h2&gt;
&lt;h2 id=&#34;hive&#34;&gt;Hive&lt;/h2&gt;
&lt;h2 id=&#34;hawqpivotal&#34;&gt;Hawq(Pivotal)&lt;/h2&gt;
&lt;p&gt;Hortonworks的HDP集成了HAWQ.&lt;/p&gt;
&lt;h2 id=&#34;impalacloudera&#34;&gt;Impala(Cloudera)&lt;/h2&gt;
&lt;p&gt;Cloudera的CHD集成了Impala.&lt;/p&gt;
&lt;h1 id=&#34;交互式分析框架nosql-on-hadoop&#34;&gt;交互式分析框架(NoSQL On Hadoop)&lt;/h1&gt;
&lt;h2 id=&#34;hbase&#34;&gt;HBase&lt;/h2&gt;
&lt;h2 id=&#34;cassandra&#34;&gt;Cassandra&lt;/h2&gt;
&lt;hr&gt;
&lt;h1 id=&#34;数据管理工具&#34;&gt;数据管理工具&lt;/h1&gt;
&lt;h2 id=&#34;sqoop&#34;&gt;Sqoop&lt;/h2&gt;
&lt;h2 id=&#34;flume&#34;&gt;Flume&lt;/h2&gt;
&lt;h1 id=&#34;消息队列&#34;&gt;消息队列&lt;/h1&gt;
&lt;h2 id=&#34;kafka&#34;&gt;Kafka&lt;/h2&gt;
&lt;h2 id=&#34;pivotal-rabbitmq&#34;&gt;Pivotal RabbitMQ&lt;/h2&gt;
&lt;hr&gt;
&lt;h1 id=&#34;dsl&#34;&gt;DSL&lt;/h1&gt;
&lt;h2 id=&#34;pig&#34;&gt;Pig&lt;/h2&gt;
&lt;hr&gt;
&lt;h1 id=&#34;workflow-and-lifecycle&#34;&gt;Workflow and Lifecycle&lt;/h1&gt;
&lt;h2 id=&#34;oozie&#34;&gt;Oozie&lt;/h2&gt;
&lt;h2 id=&#34;aurora&#34;&gt;aurora&lt;/h2&gt;
&lt;h2 id=&#34;falcon&#34;&gt;falcon&lt;/h2&gt;
&lt;hr&gt;
&lt;h1 id=&#34;security&#34;&gt;Security&lt;/h1&gt;
&lt;h2 id=&#34;sentry&#34;&gt;Sentry&lt;/h2&gt;
&lt;hr&gt;
&lt;h1 id=&#34;data-search&#34;&gt;Data search&lt;/h1&gt;
&lt;h2 id=&#34;solr&#34;&gt;Solr&lt;/h2&gt;
&lt;h2 id=&#34;nutch&#34;&gt;Nutch&lt;/h2&gt;
&lt;h2 id=&#34;lucene&#34;&gt;Lucene&lt;/h2&gt;
&lt;hr&gt;
&lt;h1 id=&#34;data-analytics&#34;&gt;Data Analytics&lt;/h1&gt;
&lt;h2 id=&#34;mahout&#34;&gt;Mahout&lt;/h2&gt;
&lt;h2 id=&#34;kuducloudera&#34;&gt;Kudu(Cloudera)&lt;/h2&gt;
&lt;hr&gt;
&lt;h1 id=&#34;misc&#34;&gt;Misc&lt;/h1&gt;
&lt;h2 id=&#34;hama&#34;&gt;hama&lt;/h2&gt;
&lt;h2 id=&#34;giraph&#34;&gt;giraph&lt;/h2&gt;
&lt;h2 id=&#34;crunch&#34;&gt;crunch&lt;/h2&gt;
&lt;h2 id=&#34;hcatalog&#34;&gt;hcatalog&lt;/h2&gt;
</description>
        </item>
        
    </channel>
</rss>
